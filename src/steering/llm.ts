// LLM client (Gemini, OpenAI, local)
export {};
